# ğŸš— KITTI-360 3D Object Detector Evaluation

This project evaluates a 3D object detector by fusing YOLOv8 instance segmentation with KITTI-360 LiDAR pointclouds. It projects depth into camera space, filters points using segmentation masks, and compares detections against ground truth 3D bounding boxes. The pipeline includes per-car precision/recall analysis, global metrics, and mAP computation across multiple IoU thresholds.

---

## ğŸ“Œ Project Overview

- ğŸ§  YOLOv8 instance segmentation on KITTI-360 camera images
- ğŸ“¡ LiDAR point cloud projection using calibration matrices
- ğŸ¯ Mask-based filtering of 3D points per car
- ğŸ“¦ Ground truth 3D bounding box matching
- ğŸ“Š Evaluation using precision, recall, F1-score, and mAP
- ğŸ¨ Rainbow depth maps and car-only projections
- ğŸ“ Excel reports and AP plots for reproducibility

---

## ğŸ› ï¸ Technologies Used

| Library        | Purpose                                                                |
|----------------|------------------------------------------------------------------------|
| `ultralytics`  | YOLOv8 segmentation and detection                                      |
| `opencv-python`| Image processing and annotation                                        |
| `numpy`        | Matrix operations and transformations                                  |
| `open3d`       | 3D visualization of point clouds and bounding boxes                    |
| `pandas`       | Excel report generation                                                |
| `matplotlib`   | AP plot visualization                                                  |
| `scikit-learn` | Precision-recall curve and mAP computation                             |

---

## ğŸ“ Folder Structure
KITTI360_3DObjectEvaluation/ 
â”œâ”€â”€ main.py                      # Full 3D fusion and evaluation pipeline   
â”œâ”€â”€ projection.py     # Rainbow depth + car-only projection images   
â”œâ”€â”€ file_graphs.py         # mAP and IoU evaluation with AP plot   
â”œâ”€â”€ requirements.txt             # Python dependencies   
â”œâ”€â”€ README.md                    # Project documentation    
â”œâ”€â”€ LICENSE                      # MIT license   
â”œâ”€â”€ data/   
â”‚   â”œâ”€â”€ data_2d_raw/                  # KITTI-360 camera images (image_00)   
â”‚   â”œâ”€â”€ data_3d_raw/                   # Velodyne pointclouds (.bin)   
â”‚   â”œâ”€â”€ calibration/             # Lidar-to-camera transformation matrix   
â”‚   â”œâ”€â”€ bboxes_3D_cam0/          # Ground truth 3D bounding boxes (JSON)   
â”€â”€ output/    
â”€â”€ Projection_images/       # Rainbow + car-only depth projections   
â”€â”€ Output/                  # mAP evaluation images   
â”€â”€ car_detections/          # Annotated images + Excel stats   
â”€â”€ car_stats.xlsx           # Evaluation metrics      
â”€â”€ AP_plot.png              # Final AP graph   


---

## ğŸš€ How to Run  
    
1. Install dependencies  
- pip install -r requirements.txt  
  
2. Prepare your data  
Place the following in the data/ folder:  
- KITTI-360 camera images (image_00)    
- Velodyne pointclouds (velodyne_points)    
- Calibration matrix (calibration)      
- Ground truth 3D bounding boxes (bboxes_3D_cam0)    

3. Run the modules      
Full pipeline with segmentation, projection, and evaluation:  
- python main.py  

Rainbow depth map and car-only projection:    
- python projection_visualizer.py  

mAP and IoU evaluation with AP plot:    
- python detection_metrics.py  

ğŸ“Š Sample Output    
ğŸ“ Annotated Image  
- ![Bounding boxes with confidence and IoU](Output/output_image_19.png)   
ğŸ“ Rainbow Depth Projection  
![- Top: full LiDAR depth map  
- Bottom: car-only points overlaid on RGB](Projection_images/projection_001.png)  
ğŸ“ Evaluation Metrics  
- ![Per-car precision, recall, F1-score  
- Global image-level metrics] (car_stats.xlsx)  
- ![Excel report](car_detection_results.xlsx)  
ğŸ“ AP Plot  
![AP Plot](C:\Users\ATHARVA\Downloads\proj\AP_plot.png)  

ğŸ“š References  
- ğŸ“˜ [KITTI-360 Dataset](https://www.cvlibs.net/datasets/kitti-360/)  
- ğŸ“˜ [Ultralytics YOLOv8](https://docs.ultralytics.com/)  
- ğŸ“˜ RWU Lidar and Radar Systems Project Guidelines  

ğŸ‘¨â€ğŸ“ Author
Atharva U. Dahitule  
Masterâ€™s Student, Mechatronics Engineering  
RWU Hochschule Ravensburg-Weingarten, Germany
